import re

import streamlit as st
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from vk_api import VkApi


@st.cache_resource()
def load_model():
    model = BertForSequenceClassification.from_pretrained(
        "Aniemore/rubert-tiny-emotion-russian-cedr-m7"
    )
    tokenizer = BertTokenizer.from_pretrained(
        "Aniemore/rubert-tiny-emotion-russian-cedr-m7"
    )
    return model, tokenizer


def parse_link(link):
    pattern = re.compile(
        r"https://vk\.com/[A-Za-z]+\?w=wall-[0-9]+_[0-9]+", re.IGNORECASE
    )
    if pattern.match(link):
        ids = link.split("w=wall", 1)[1].split("_")
        return int(ids[0]), int(ids[1]), True
    else:
        return 0, 0, False


def get_comments(owner_id, post_id, comments_num, vk):
    comments = []
    i = 0
    prev = -1
    while i < 35 and len(comments) < comments_num and len(comments) != prev:
        current_num = min(comments_num - len(comments), 100)
        prev = len(comments)
        comments_buf = vk.wall.getComments(
            owner_id=owner_id,
            post_id=post_id,
            count=current_num,
            offset=i * 100,
            thread_items_count=10,
        )["items"]
        comments += comments_buf
        for comment in comments_buf:
            if comment["thread"]["items"]:
                comments += comment["thread"]["items"]
        i += 1
    return comments


def main():
    session = VkApi(token=st.secrets["VK_TOKEN"])
    vk = session.get_api()
    st.title(
        "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾ÐºÑ€Ð°Ñ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¿Ð¾Ð´ Ð¿Ð¾ÑÑ‚Ð¾Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð° Ð’ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ðµ"
    )
    st.write("ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾ÐºÑ€Ð°ÑÐ° ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²")

    emoji_dict = {
        "neutral": "ðŸ˜",
        "anger": "ðŸ˜ ",
        "enthusiasm": "ðŸ¤©",
        "sadness": "ðŸ˜”",
        "fear": "ðŸ˜¨",
        "happiness": "ðŸ˜Š",
        "disgust": "ðŸ¤¢",
    }

    model, tokenizer = load_model()

    user_input = st.text_input(
        "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÑÑÑ‹Ð»ÐºÑƒ Ð½Ð° Ð¿Ð¾ÑÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð° Ð’ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ðµ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ñ†ÐµÐ½Ð¸Ñ‚ÑŒ Ð¸Ñ… ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾ÐºÑ€Ð°Ñ:"
    )
    comments_num = st.number_input(
        "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3500, ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 10 Ð²Ð»Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ñ… "
        "ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¸Ð· ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð²ÐµÑ‚ÐºÐ¸)",
        min_value=0,
        max_value=3500,
        step=1,
    )

    if st.button("ÐžÑ†ÐµÐ½Ð¸Ñ‚ÑŒ"):
        emotions = {
            "neutral": 0,
            "anger": 0,
            "enthusiasm": 0,
            "sadness": 0,
            "fear": 0,
            "happiness": 0,
            "disgust": 0,
        }
        owner_id, post_id, is_ok = parse_link(user_input)
        if is_ok:
            comments = get_comments(int(owner_id), int(post_id), comments_num, vk)

            for comment in comments:
                input_ids = tokenizer.encode(comment["text"], return_tensors="pt")

                with torch.no_grad():
                    logits = model(input_ids).logits
                predicted_class_id = logits.argmax().item()
                emotions[model.config.id2label[predicted_class_id]] += 1

            for emotion, count in emotions.items():
                emoji = emoji_dict.get(emotion)
                st.write(f"{emoji} {count}")
            st.write(f"Ð’ÑÐµÐ³Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²: {sum(emotions.values())}")

        else:
            st.warning(
                "Ð’Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð²Ð²ÐµÑÑ‚Ð¸ ÑÑÑ‹Ð»ÐºÑƒ Ð½Ð° Ð¿Ð¾ÑÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð° Ð’ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ðµ Ð² Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ: https://vk.com/groupname?w=wall-72378974_8296684"
            )


if __name__ == "__main__":
    main()
